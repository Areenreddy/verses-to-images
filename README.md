# verses-to-images

# Abstract

This research explores the combination of textual and visual elements in the domain of poem summarization, aiming to enhance the comprehension of poetic content. Our approach involves generating concise and meaningful summaries for poems through the use of language models such as GPT 3.5 and GPT 4. To the best of our knowledge, none of the prior works related to summarization have implemented large language models (LLMs) for the generation of poem summaries. We introduce a novel multimodal dataset that combines textual excerpts with corresponding visual representations generated using diffusion models for image generation, namely LLM grounded, stable diffusion, and SDXL Turbo, marking a significant advancement in the resources available for poem analysis. Furthermore, we present quantitative results demonstrating the efficacy of our approach, showcasing improvements over the existing state of art for poem summary generation. Through the creation of three images for each poem summary, we provide visual cues that augment the understanding of poetic themes and motifs. Additionally, we conduct a comprehensive comparison of the generated images, showcasing the benefits and drawbacks of different visual representations in specific contexts. This study not only expands the toolkit for poem summarization but also contributes to the broader exploration of multimodal data integration in literary analysis.
